{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c8a04b",
   "metadata": {},
   "source": [
    "# Multi-Classification Machine Learning for Malware Analysis\n",
    "## 9 Types of Malware in this dataset:\n",
    "1. Ramnit         - RAT\n",
    "2. Lollipop       - Adware\n",
    "3. Kelihos_ver3   - RAT\n",
    "4. Vundo          - Adware\n",
    "5. Simda          - Botnet\n",
    "6. Tracur         - Malicious Browser Plugin\n",
    "7. Kelihos_ver1   - RAT\n",
    "8. Obfuscator.ACY - Obfuscates other malware/information\n",
    "9. Gatak          - RAT\n",
    "\n",
    "## Game Plan:\n",
    "\n",
    "- Create Functions\n",
    "    - List files in a directory /\n",
    "    - Regex Search within a file\n",
    "    - Replace parts of string (perhaps predefined file path and extension) /\n",
    "    - Pull list of instructions out of the file (newline separated)\n",
    "    - Sort a dictionary /\n",
    "    - Print a DF /\n",
    "    \n",
    "\n",
    "## Questions:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9678f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9004337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listFilesInDirectory(directoryContainingFiles):\n",
    "    return glob.glob(directoryContainingFiles) \n",
    "\n",
    "def stripFilePathAndExtension(filePath, prefixToStrip, suffixToStrip):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    return filePath\n",
    "\n",
    "def replaceFilePathAndExtension(filePath, prefixToStrip, prefixToInsert, suffixToStrip, suffixToInsert):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    return filePath\n",
    "\n",
    "def printDataFrame(dataframe):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(dataframe)\n",
    "\n",
    "def zeroOutDataframe(dataframe):\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    return dataframe\n",
    "\n",
    "def countEntriesInDataframe(dataframe):\n",
    "    return np.count_nonzero(dataframe)\n",
    "\n",
    "def sortDictionary(dictionary):\n",
    "    returnVal = sorted(dict(Counter(dictionary)).items(), key=lambda kv:\n",
    "                 (kv[1], kv[0]))\n",
    "    return returnVal\n",
    "\n",
    "def fileNewlineIntoList(filePath):\n",
    "    lineList = []\n",
    "    with open(filePath) as openFile:\n",
    "        for line in openFile:\n",
    "            temp = line.strip()\n",
    "            lineList.append(temp)\n",
    "    return lineList\n",
    "\n",
    "def stripNewlineAndWhitespace(textStringToStrip):\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\t\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\n\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\" \",\"\")\n",
    "    return textStringToStrip\n",
    "\n",
    "def stripNewlineAndWhitespaceFromList(listToStrip):\n",
    "    for i in range(0,len(listToStrip)):\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\t\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\n\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\" \",\"\")\n",
    "    return listToStrip\n",
    "\n",
    "def regexSearchFile(filePath, regexPattern):\n",
    "    with open(filePath) as openFile:\n",
    "        matches = re.findall(regexPattern, openFile.read())\n",
    "    openFile.close()\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c1528",
   "metadata": {},
   "source": [
    "## Pulling the files from the dataset into the class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d8cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need a DF of every file and it's class for sorting\n",
    "fullFileNamesListFromCSV = pd.read_csv(\"/home/eddy/machine-learning/data/trainLabels.csv\")\n",
    "fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "backupFileList = listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/*\")\n",
    "\n",
    "for file in backupFileList: # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "    fileClean = stripFilePathAndExtension(file,\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "    #shutil.copyfile(file,\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "    #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08339e72",
   "metadata": {},
   "source": [
    "## Creating the Pandas DataFrame for the malware classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f48d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructionList = fileNewlineIntoList(\"/home/eddy/machine-learning/instructionListComplete.txt\")\n",
    "instructionList = [instruction.lower() for instruction in instructionList] # Making all instructions lowercase\n",
    "\n",
    "filePathToNameDict = {}\n",
    "classOneFileList = listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\")\n",
    "fileNameList = classOneFileList\n",
    "\n",
    "for i in range(0, len(fileNameList)): \n",
    "    strippedFile = stripFilePathAndExtension(fileNameList[i], \"/home/eddy/machine-learning/data/dataset-subset/class-1/\", \".asm\")\n",
    "    filePathToNameDict[strippedFile] = fileNameList[i]\n",
    "    fileNameList[i] = strippedFile\n",
    "\n",
    "dataframeClassOne = zeroOutDataframe(pd.DataFrame(columns=instructionList,index=fileNameList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3941ad91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_33471/596876114.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33471/596876114.py:6: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_33471/596876114.py:6: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    }
   ],
   "source": [
    "#for instruction in instructionList:\n",
    "for file in filePathToNameDict.keys(): # Go through every file in our directory\n",
    "    fileDirectory = filePathToNameDict[file] # Convert using dict here\n",
    "    instructionsForThisFile = stripNewlineAndWhitespaceFromList(regexSearchFile(fileDirectory,\"(?:\\t{3,7}       (?!db|dd)[a-zA-Z]{2,6} {1,})\")) # cleaning and pulling instructions\n",
    "\n",
    "    pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up   \n",
    "    for i in range(0, len(pandasSeriesTest[0])):\n",
    "        dataframeClassOne.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
    "    \n",
    "    #Optional cleaning options for my DF to merge dupe columns and group them up\n",
    "    dataframeClassOne = dataframeClassOne.groupby(axis=1, level=0).sum()\n",
    "    dataframeClassOne = dataframeClassOne.loc[:, (dataframeClassOne != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a16debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeClassOne.to_csv(\"/home/eddy/machine-learning/data/datasetClassOne.csv\")\n",
    "print(dataframeClassOne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
