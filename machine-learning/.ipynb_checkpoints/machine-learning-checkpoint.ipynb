{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c8a04b",
   "metadata": {},
   "source": [
    "# Multi-Classification Machine Learning for Malware Analysis\n",
    "## 9 Types of Malware in this dataset:\n",
    "1. Ramnit         - RAT\n",
    "2. Lollipop       - Adware\n",
    "3. Kelihos_ver3   - RAT\n",
    "4. Vundo          - Adware\n",
    "5. Simda          - Botnet\n",
    "6. Tracur         - Malicious Browser Plugin\n",
    "7. Kelihos_ver1   - RAT\n",
    "8. Obfuscator.ACY - Obfuscates other malware/information\n",
    "9. Gatak          - RAT\n",
    "\n",
    "## Game Plan:\n",
    "\n",
    "- Look into creating more metrics to show off my model\n",
    "- Improve the way I import data for the model\n",
    "- Explain my code and solution in detail\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529f870",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9678f78f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n",
      "/bin/bash: line 1: {sys.executable}: command not found\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install jupyterthemes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import shutil\n",
    "from pathlib import Path #Convert all directory accesses to this\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c088df",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9004337c",
   "metadata": {
    "code_folding": [
     0,
     3,
     9,
     14,
     18,
     22,
     25,
     30,
     38,
     44,
     51,
     57,
     65,
     68,
     74,
     84,
     90
    ]
   },
   "outputs": [],
   "source": [
    "def listFilesInDirectory(directoryContainingFiles):\n",
    "    return glob.glob(directoryContainingFiles) \n",
    "\n",
    "def stripFilePathAndExtension(filePath, prefixToStrip, suffixToStrip):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    #return filePath\n",
    "    return Path(filePath).stem\n",
    "\n",
    "def replaceFilePathAndExtension(filePath, prefixToStrip, prefixToInsert, suffixToStrip, suffixToInsert):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    return filePath\n",
    "\n",
    "def printDataFrame(dataframe):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(dataframe)\n",
    "\n",
    "def zeroOutDataframe(dataframe):\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    return dataframe\n",
    "\n",
    "def countEntriesInDataframe(dataframe):\n",
    "    return np.count_nonzero(dataframe)\n",
    "\n",
    "def sortDictionary(dictionary):\n",
    "    returnVal = sorted(dict(Counter(dictionary)).items(), key=lambda kv:\n",
    "                 (kv[1], kv[0]))\n",
    "    return returnVal\n",
    "\n",
    "def fileNewlineIntoList(filePath):\n",
    "    lineList = []\n",
    "    with open(filePath) as openFile:\n",
    "        for line in openFile:\n",
    "            temp = line.strip()\n",
    "            lineList.append(temp)\n",
    "    return lineList\n",
    "\n",
    "def stripNewlineAndWhitespace(textStringToStrip):\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\t\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\n\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\" \",\"\")\n",
    "    return textStringToStrip\n",
    "\n",
    "def stripNewlineAndWhitespaceFromList(listToStrip):\n",
    "    for i in range(0,len(listToStrip)):\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\t\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\n\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\" \",\"\")\n",
    "    return listToStrip\n",
    "\n",
    "def regexSearchFile(filePath, regexPattern):\n",
    "    with open(filePath) as openFile:\n",
    "        matches = re.findall(regexPattern, openFile.read())\n",
    "    openFile.close()\n",
    "    return matches\n",
    "\n",
    "def cleanFileNameList(fileNameList,malwareClass):\n",
    "    filePathToNameDict = {}\n",
    "    for i in range(0, len(fileNameList)): \n",
    "        strippedFile = stripFilePathAndExtension(fileNameList[i], \"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(malwareClass)+\"/\", \".asm\") #FIX THIS TO ALLOW FOR DIFFERENT CLASSES\n",
    "        filePathToNameDict[strippedFile] = fileNameList[i]\n",
    "        fileNameList[i] = strippedFile\n",
    "    return fileNameList\n",
    "\n",
    "def generateClassDataFrame(instructionList,fileNameListForClass):\n",
    "    return zeroOutDataframe(pd.DataFrame(columns=instructionList,index=fileNameListForClass))\n",
    "\n",
    "def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Old and working before I tried the next version\n",
    "    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "    for file in backupFileList: # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "        fileClean = stripFilePathAndExtension(file,\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "        shutil.copyfile(file,\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "#def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Experimental\n",
    "    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "    for fileIndex in range(0,len(backupFileList)): # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "        fileClean = stripFilePathAndExtension(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "        try:\n",
    "            shutil.copyfile(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        except:\n",
    "            fileIndex = fileIndex + 1\n",
    "        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "\n",
    "def generateFilenameToDirectoryDict(fileDirectory):\n",
    "    filePathToNameDict = {}\n",
    "    for file in fileDirectory:\n",
    "        filePathToNameDict[Path(file).stem] = file\n",
    "    return filePathToNameDict\n",
    "\n",
    "def populateMalwareDataframe(fileDirectoryTopLevel,instructionList):\n",
    "\n",
    "    filePathToNameDict = generateFilenameToDirectoryDict(listFilesInDirectory(fileDirectoryTopLevel))\n",
    "    dataFrame = zeroOutDataframe(pd.DataFrame(columns=instructionList,index=filePathToNameDict.keys()))\n",
    "\n",
    "    for file in filePathToNameDict.keys(): # Go through every file in our directory\n",
    "        fileDirectory = filePathToNameDict[file] # Convert using dict here\n",
    "        instructionsForThisFile = stripNewlineAndWhitespaceFromList(regexSearchFile(fileDirectory,\"(?:\\t{3,7}       (?!db|dd)[a-zA-Z]{2,6} {1,})\")) # cleaning and pulling instructions\n",
    "\n",
    "        pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up   \n",
    "        for i in range(0, len(pandasSeriesTest[0])):\n",
    "            dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
    "        \n",
    "        #Optional cleaning options for my DF to merge dupe columns and group them up\n",
    "        dataFrame = dataFrame.groupby(axis=1, level=0).sum() # Merges dupe columns\n",
    "        #dataFrame = dataFrame.loc[:, (dataFrame != 0).any(axis=0)] # Removes columns with no values\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c1528",
   "metadata": {},
   "source": [
    "## Pulling the files from the dataset into the class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d8cd72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#moveFilesToClassFolders(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/*\"),pd.read_csv(\"/home/eddy/machine-learning/data/trainLabels.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08339e72",
   "metadata": {},
   "source": [
    "## Creating the Pandas DataFrame for the malware classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f48d380",
   "metadata": {
    "code_folding": [
     10,
     23,
     35,
     47,
     59,
     71,
     83,
     95,
     107
    ],
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
      "/tmp/ipykernel_31592/4251463862.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n"
     ]
    }
   ],
   "source": [
    "instructionList = fileNewlineIntoList(\"/home/eddy/machine-learning/instructionListComplete.txt\")\n",
    "instructionList = [instruction.lower() for instruction in instructionList] # Making all instructions lowercase\n",
    "\n",
    "dataframeClassOne = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\"),1))\n",
    "dataframeClassOne = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\",instructionList)\n",
    "dataframeClassOne.to_csv(\"/home/eddy/machine-learning/data/datasetClassOne.csv\")\n",
    "#dataframeClassOne = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "dataframeClassOne = zeroOutDataframe(dataframeClassOne)\n",
    "dataframeClassOne.loc[~(dataframeClassOne==0).all(axis=1)]\n",
    "dataframeClassOne.insert(0,\"class\",1)\n",
    "#dataframeClassOneNormalised = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "#dataframeClassOneNormalised = zeroOutDataframe(dataframeClassOneNormalised)\n",
    "#dataframeClassOneNormalised.loc[~(dataframeClassOneNormalised==0).all(axis=1)]\n",
    "#dataframeClassOneNormalised.insert(0,\"class\",1)\n",
    "\n",
    "\n",
    "dataframeClassTwo = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm\"),2))\n",
    "dataframeClassTwo = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm\",instructionList)\n",
    "dataframeClassTwo.to_csv(\"/home/eddy/machine-learning/data/datasetClassTwo.csv\")\n",
    "#dataframeClassTwo = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "dataframeClassTwo = zeroOutDataframe(dataframeClassTwo)\n",
    "dataframeClassTwo.loc[~(dataframeClassTwo==0).all(axis=1)]\n",
    "dataframeClassTwo.insert(0,\"class\",2)\n",
    "#dataframeClassTwoNormalised = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "#dataframeClassTwoNormalised = zeroOutDataframe(dataframeClassTwoNormalised)\n",
    "#dataframeClassTwoNormalised.loc[~(dataframeClassTwoNormalised==0).all(axis=1)]\n",
    "#dataframeClassTwoNormalised.insert(0,\"class\",2)\n",
    "\n",
    "dataframeClassThree = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm\"),3))\n",
    "dataframeClassThree = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm\",instructionList)\n",
    "dataframeClassThree.to_csv(\"/home/eddy/machine-learning/data/datasetClassThree.csv\")\n",
    "#dataframeClassThree = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "dataframeClassThree = zeroOutDataframe(dataframeClassThree)\n",
    "dataframeClassThree.loc[~(dataframeClassThree==0).all(axis=1)]\n",
    "dataframeClassThree.insert(0,\"class\",3)\n",
    "#dataframeClassThreeNormalised = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "#dataframeClassThreeNormalised = zeroOutDataframe(dataframeClassThreeNormalised)\n",
    "#dataframeClassThreeNormalised.loc[~(dataframeClassThreeNormalised==0).all(axis=1)]\n",
    "#dataframeClassThreeNormalised.insert(0,\"class\",3)\n",
    "\n",
    "dataframeClassFour = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm\"),4))\n",
    "dataframeClassFour = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm\",instructionList)\n",
    "dataframeClassFour.to_csv(\"/home/eddy/machine-learning/data/datasetClassFour.csv\")\n",
    "#dataframeClassFour = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "dataframeClassFour= zeroOutDataframe(dataframeClassFour)\n",
    "dataframeClassFour.loc[~(dataframeClassFour==0).all(axis=1)]\n",
    "dataframeClassFour.insert(0,\"class\",4)\n",
    "#dataframeClassFourNormalised = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "#dataframeClassFourNormalised= zeroOutDataframe(dataframeClassFourNormalised)\n",
    "#dataframeClassFourNormalised.loc[~(dataframeClassFourNormalised==0).all(axis=1)]\n",
    "#dataframeClassFourNormalised.insert(0,\"class\",4)\n",
    "\n",
    "dataframeClassFive = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm\"),5))\n",
    "dataframeClassFive = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm\",instructionList)\n",
    "dataframeClassFive.to_csv(\"/home/eddy/machine-learning/data/datasetClassFive.csv\")\n",
    "#dataframeClassFive = dataframeClassFive.div(dataframeClassFive.sum(axis=1), axis=0)\n",
    "dataframeClassFive = zeroOutDataframe(dataframeClassFive)\n",
    "dataframeClassFive.loc[~(dataframeClassFive==0).all(axis=1)]\n",
    "dataframeClassFive.insert(0,\"class\",5)\n",
    "#dataframeClassFiveNormalised = zeroOutDataframe(dataframeClassFiveNormalised)\n",
    "#dataframeClassFiveNormalised.loc[~(dataframeClassFiveNormalised==0).all(axis=1)]\n",
    "#dataframeClassFiveNormalised.to_csv(\"/home/eddy/machine-learning/data/datasetClassFiveNormalised.csv\")\n",
    "#dataframeClassFiveNormalised.insert(0,\"class\",5)\n",
    "\n",
    "dataframeClassSix = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm\"),6))\n",
    "dataframeClassSix = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm\",instructionList)\n",
    "dataframeClassSix.to_csv(\"/home/eddy/machine-learning/data/datasetClassSix.csv\")\n",
    "#dataframeClassSix = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "dataframeClassSix = zeroOutDataframe(dataframeClassSix)\n",
    "dataframeClassSix.loc[~(dataframeClassSix==0).all(axis=1)]\n",
    "dataframeClassSix.insert(0,\"class\",6)\n",
    "#dataframeClassSixNormalised = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "#dataframeClassSixNormalised = zeroOutDataframe(dataframeClassSixNormalised)\n",
    "#dataframeClassSixNormalised.loc[~(dataframeClassSixNormalised==0).all(axis=1)]\n",
    "#dataframeClassSixNormalised.insert(0,\"class\",6)\n",
    "\n",
    "dataframeClassSeven = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm\"),7))\n",
    "dataframeClassSeven = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm\",instructionList)\n",
    "dataframeClassSeven.to_csv(\"/home/eddy/machine-learning/data/datasetClassSeven.csv\")\n",
    "#dataframeClassSeven = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "dataframeClassSeven = zeroOutDataframe(dataframeClassSeven)\n",
    "dataframeClassSeven.loc[~(dataframeClassSeven==0).all(axis=1)]\n",
    "dataframeClassSeven.insert(0,\"class\",7)\n",
    "#dataframeClassSevenNormalised = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "#dataframeClassSevenNormalised = zeroOutDataframe(dataframeClassSevenNormalised)\n",
    "#dataframeClassSevenNormalised.loc[~(dataframeClassSevenNormalised==0).all(axis=1)]\n",
    "#dataframeClassSevenNormalised.insert(0,\"class\",7)\n",
    "\n",
    "dataframeClassEight = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm\"),8))\n",
    "dataframeClassEight = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm\",instructionList)\n",
    "dataframeClassEight.to_csv(\"/home/eddy/machine-learning/data/datasetClassEight.csv\")\n",
    "#dataframeClassEight = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "dataframeClassEight = zeroOutDataframe(dataframeClassEight)\n",
    "dataframeClassEight.loc[~(dataframeClassEight==0).all(axis=1)]\n",
    "dataframeClassEight.insert(0,\"class\",8)\n",
    "#dataframeClassEightNormalised = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "#dataframeClassEightNormalised = zeroOutDataframe(dataframeClassEightNormalised)\n",
    "#dataframeClassEightNormalised.loc[~(dataframeClassEightNormalised==0).all(axis=1)]\n",
    "#dataframeClassEightNormalised.insert(0,\"class\",8)\n",
    "\n",
    "dataframeClassNine = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm\"),9))\n",
    "dataframeClassNine = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm\",instructionList)\n",
    "dataframeClassNine.to_csv(\"/home/eddy/machine-learning/data/datasetClassNine.csv\")\n",
    "#dataframeClassNine = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "dataframeClassNine = zeroOutDataframe(dataframeClassNine)\n",
    "dataframeClassNine.loc[~(dataframeClassNine==0).all(axis=1)]\n",
    "dataframeClassNine.insert(0,\"class\",9)\n",
    "#dataframeClassNineNormalised = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "#dataframeClassNineNormalised = zeroOutDataframe(dataframeClassNineNormalised)\n",
    "#dataframeClassNineNormalised.loc[~(dataframeClassNineNormalised==0).all(axis=1)]\n",
    "#dataframeClassNineNormalised.insert(0,\"class\",9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd53ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframesNormalisedList = [dataframeClassOneNormalised,dataframeClassTwoNormalised,dataframeClassThreeNormalised,dataframeClassFourNormalised,dataframeClassFiveNormalised,dataframeClassSixNormalised,dataframeClassSevenNormalised,dataframeClassEightNormalised,dataframeClassNineNormalised]\n",
    "dataframesList = [dataframeClassOne,dataframeClassTwo,dataframeClassThree,dataframeClassFour,dataframeClassFive,dataframeClassSix,dataframeClassSeven,dataframeClassEight,dataframeClassNine]\n",
    "finalDF = pd.concat(dataframesList).drop_duplicates()\n",
    "finalDF = finalDF.drop([\"assume\",\"align\"],axis=1) # Error, seems like they're gone already\n",
    "finalDF = zeroOutDataframe(finalDF)\n",
    "finalDF.loc[~(finalDF==0).all(axis=1)]\n",
    "finalDF = finalDF.loc[:, (finalDF != 0).any(axis=0)] # Removes columns with no values\n",
    "finalDF = finalDF.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e5ba3",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a16debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1028 entries, 0m94tRnhgpsAUuY1L8KC to 2eSoCjQzDri3E0cuxUYb\n",
      "Columns: 263 entries, class to vrcpss\n",
      "dtypes: float64(262), int64(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Importing sklearn and getting basic info about my training set\n",
    "#Merge all data into one DF with labels intact\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "finalDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09a03b",
   "metadata": {},
   "source": [
    "## Splitting the data into train+test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3795c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset rows and columns: (616, 263)\n",
      "Test Dataset rows and columns: (206, 263)\n",
      "Validation Dataset rows and columns: (206, 263)\n"
     ]
    }
   ],
   "source": [
    "#Dividing up the dataset into train, validate and test sets\n",
    "trainDF, testAndValidDF = train_test_split(finalDF, test_size=0.4)\n",
    "testDF, validDF = train_test_split(testAndValidDF, test_size=0.5)\n",
    "\n",
    "print(f\"Training Dataset rows and columns: {trainDF.shape}\")\n",
    "print(f\"Test Dataset rows and columns: {testDF.shape}\")\n",
    "print(f\"Validation Dataset rows and columns: {validDF.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cda6a",
   "metadata": {},
   "source": [
    "## Training Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0874cb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    616.000000\n",
       "mean       3.810065\n",
       "std        2.664057\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        6.000000\n",
       "max        9.000000\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "#not doing sns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caea71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training stats based on the trainDF dataset\n",
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "trainStats = trainStats.transpose()\n",
    "trainStats.to_csv(\"/home/eddy/traindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbae27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "206\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "#Creating Labels\n",
    "trainLabels = trainDF.pop(\"class\")\n",
    "testLabels = testDF.pop(\"class\")\n",
    "validLabels = validDF.pop(\"class\")\n",
    "\n",
    "print(len(trainLabels))\n",
    "print(len(testLabels))\n",
    "print(len(validLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d56d5",
   "metadata": {},
   "source": [
    "## Data Normalisation/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6db494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>aam</th>\n",
       "      <th>adc</th>\n",
       "      <th>add</th>\n",
       "      <th>addpd</th>\n",
       "      <th>addps</th>\n",
       "      <th>addsd</th>\n",
       "      <th>addss</th>\n",
       "      <th>and</th>\n",
       "      <th>andnps</th>\n",
       "      <th>...</th>\n",
       "      <th>cmovp</th>\n",
       "      <th>end</th>\n",
       "      <th>VxDJmp</th>\n",
       "      <th>fcmovb</th>\n",
       "      <th>fcmovu</th>\n",
       "      <th>ht</th>\n",
       "      <th>retfw</th>\n",
       "      <th>setp</th>\n",
       "      <th>svts</th>\n",
       "      <th>vrcpss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2sf3AQd9MjP1xcLFRYyo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0df4cbsTBCn1VGW8lQRv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3n1LAdlCtkErg09OIfFx</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1GRsOmJXetEkqIraBuSd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0VfuK267xTdeBcmLaCp1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0KgE6ksUeytoHfl2cT4r</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1UJIV2ntdkuWgzvFr4pm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3KkOaclun82iE95PSsJm</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0dkuzUXLTEFwW71vP5bS</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3DfvjbGBnePmskyhpCT2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      aad  aam  adc    add  addpd  addps  addsd  addss    and  \\\n",
       "2sf3AQd9MjP1xcLFRYyo  0.0  0.0  0.0  158.0    0.0    0.0    0.0    0.0   51.0   \n",
       "0df4cbsTBCn1VGW8lQRv  0.0  0.0  0.0   71.0    0.0    0.0    0.0    0.0    7.0   \n",
       "3n1LAdlCtkErg09OIfFx  0.0  0.0  2.0   90.0    0.0    0.0    0.0    0.0   26.0   \n",
       "1GRsOmJXetEkqIraBuSd  0.0  0.0  0.0  403.0    0.0    0.0    0.0    0.0  243.0   \n",
       "0VfuK267xTdeBcmLaCp1  0.0  0.0  2.0  398.0    0.0    0.0    0.0    0.0  224.0   \n",
       "0KgE6ksUeytoHfl2cT4r  0.0  0.0  0.0    4.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1UJIV2ntdkuWgzvFr4pm  0.0  0.0  7.0  129.0    0.0    0.0    0.0    0.0  100.0   \n",
       "3KkOaclun82iE95PSsJm  0.0  0.0  0.0   65.0    0.0    0.0    0.0    0.0    3.0   \n",
       "0dkuzUXLTEFwW71vP5bS  0.0  0.0  0.0   65.0    0.0    0.0    0.0    0.0    5.0   \n",
       "3DfvjbGBnePmskyhpCT2  0.0  0.0  5.0  100.0    0.0    0.0    0.0    0.0    8.0   \n",
       "\n",
       "                      andnps  ...  cmovp  end  VxDJmp  fcmovb  fcmovu   ht  \\\n",
       "2sf3AQd9MjP1xcLFRYyo     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "0df4cbsTBCn1VGW8lQRv     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "3n1LAdlCtkErg09OIfFx     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "1GRsOmJXetEkqIraBuSd     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "0VfuK267xTdeBcmLaCp1     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "0KgE6ksUeytoHfl2cT4r     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "1UJIV2ntdkuWgzvFr4pm     0.0  ...    0.0  1.0     0.0     0.0     0.0  0.0   \n",
       "3KkOaclun82iE95PSsJm     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "0dkuzUXLTEFwW71vP5bS     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "3DfvjbGBnePmskyhpCT2     0.0  ...    0.0  0.0     0.0     0.0     0.0  0.0   \n",
       "\n",
       "                      retfw  setp  svts  vrcpss  \n",
       "2sf3AQd9MjP1xcLFRYyo    0.0   0.0   0.0     0.0  \n",
       "0df4cbsTBCn1VGW8lQRv    0.0   0.0   0.0     0.0  \n",
       "3n1LAdlCtkErg09OIfFx    0.0   0.0   0.0     0.0  \n",
       "1GRsOmJXetEkqIraBuSd    0.0   0.0   0.0     0.0  \n",
       "0VfuK267xTdeBcmLaCp1    0.0   0.0   0.0     0.0  \n",
       "0KgE6ksUeytoHfl2cT4r    0.0   0.0   0.0     0.0  \n",
       "1UJIV2ntdkuWgzvFr4pm    0.0   0.0   0.0     0.0  \n",
       "3KkOaclun82iE95PSsJm    0.0   0.0   0.0     0.0  \n",
       "0dkuzUXLTEFwW71vP5bS    0.0   0.0   0.0     0.0  \n",
       "3DfvjbGBnePmskyhpCT2    0.0   0.0   0.0     0.0  \n",
       "\n",
       "[10 rows x 262 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normaliseData(data):\n",
    "    #return (data -trainStats[\"mean\"]) / trainStats['std'] #Works fine, experimenting with the OTHER\n",
    "    return data\n",
    "    #return data.div(data.sum(axis=1), axis=0)\n",
    "\n",
    "normalisedTrainDF = normaliseData(trainDF)\n",
    "normalisedTestDF = normaliseData(testDF)\n",
    "normalisedValidDF = normaliseData(validDF)\n",
    "\n",
    "normalisedTrainDF = normalisedTrainDF.replace(np.nan,0)\n",
    "normalisedTestDF = normalisedTestDF.replace(np.nan,0)\n",
    "normalisedValidDF = normalisedValidDF.replace(np.nan,0)\n",
    "normalisedTrainDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f80820",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1181ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "model = svm.SVC(C = 1.5,\n",
    "                kernel='linear')\n",
    "modelPoly = svm.SVC(C = 1.5,\n",
    "                   kernel='poly')\n",
    "modelRBF = svm.SVC(C = 1.5,\n",
    "                   kernel='rbf')\n",
    "modelSig = svm.SVC(C = 1.5,\n",
    "                   kernel='sigmoid')\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(normalisedTrainDF, trainLabels)\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(normalisedTrainDF)\n",
    "\n",
    "modelPoly.fit(normalisedTrainDF, trainLabels)\n",
    "y_predPoly = modelPoly.predict(normalisedTrainDF)\n",
    "\n",
    "modelRBF.fit(normalisedTrainDF, trainLabels)\n",
    "y_predRBF = modelRBF.predict(normalisedTrainDF)\n",
    "\n",
    "modelSig.fit(normalisedTrainDF, trainLabels)\n",
    "y_predSig = modelSig.predict(normalisedTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964b3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    2Jfm9sAlG3DWCI0cpSYw\n",
      "1    1l5V2AwZS9ixLMmecCkp\n",
      "2    2bf65CdkZTUGXjzq9KNJ\n",
      "3    1rSPXYcLpO9HQWwGz8fi\n",
      "1    3fgX5GuthkIcJaTvP9UN\n",
      "3    3b7cK2nPtTHIQ658wsYk\n",
      "9    0gcZkSFr7VnEmLPbTxUe\n",
      "1    2Qn5kEMv9rXOHBaVWsYf\n",
      "3    2LeQVofH8Jl4da69AUxk\n",
      "2    1WysH96E7LwIYafNrmO3\n",
      "Predicted values: [3 1 2 3 1 3 9 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "exampleBatch = normalisedTestDF[:10]\n",
    "\n",
    "exampleResult = model.predict(exampleBatch)\n",
    "\n",
    "print(pd.Series(list(exampleBatch.index),index=exampleResult).to_string())\n",
    "print(f\"Predicted values: {exampleResult}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426cde3",
   "metadata": {},
   "source": [
    "## Checking how training went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b4bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Train Accuracy:  0.9951298701298701\n",
      "Poly Train Accuracy:  0.4074675324675325\n",
      "RBF Train Accuracy:  0.5568181818181818\n",
      "Sigmoid Train Accuracy:  0.44155844155844154\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#print(normalisedTrainDF.shape)\n",
    "normalisedTrainDF = normalisedTrainDF[np.isfinite(normalisedTrainDF).all(1)]\n",
    "#print(normalisedTrainDF.shape)\n",
    "\n",
    "#print(len(y_pred))\n",
    "#y_pred = model.predict(normalisedTrainDF)\n",
    "print(\"Linear Train Accuracy: \",metrics.accuracy_score(trainLabels,y_pred))\n",
    "print(\"Poly Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predPoly))\n",
    "print(\"RBF Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predRBF))\n",
    "print(\"Sigmoid Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predSig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c34661fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Valid Accuracy:  0.8932038834951457\n",
      "Linear Valid Accuracy:  0.8932038834951457\n"
     ]
    }
   ],
   "source": [
    "#newNormalisedValidDF = zeroOutDataframe(normalisedValidDF)\n",
    "#newNormalisedValidDF = newNormalisedValidDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "y_pred = model.predict(newNormalisedValidDF)\n",
    "print(\"Linear Valid Accuracy: \",metrics.accuracy_score(validLabels,y_pred))\n",
    "print(\"Linear Valid Accuracy: \",metrics.accuracy_score(validLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20b5b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206, 262)\n",
      "(206, 262)\n",
      "Test Accuracy:  0.9514563106796117\n"
     ]
    }
   ],
   "source": [
    "#newNormalisedTestDF = zeroOutDataframe(normalisedTestDF)\n",
    "#newNormalisedTestDF = newNormalisedTestDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "y_pred = model.predict(newNormalisedTestDF)\n",
    "print(\"Test Accuracy: \",metrics.accuracy_score(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3022aaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot()\n",
    "predictResults = model.predict(newNormalisedTestDF)\n",
    "cm = confusion_matrix(predictResults,predictResults)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix - Linear\")\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax=ax); #Semicolon removes the annoying text above the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d36b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.87      0.86        31\n",
      "           2       0.98      0.94      0.96        48\n",
      "           3       1.00      1.00      1.00        71\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.60      0.75      0.67         4\n",
      "           7       1.00      1.00      1.00         4\n",
      "           8       0.96      1.00      0.98        22\n",
      "           9       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.95       206\n",
      "   macro avg       0.81      0.82      0.82       206\n",
      "weighted avg       0.95      0.95      0.95       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/eddy/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/eddy/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
