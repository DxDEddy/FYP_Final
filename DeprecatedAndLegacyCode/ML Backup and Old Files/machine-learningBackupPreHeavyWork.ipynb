{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04c8a04b",
   "metadata": {},
   "source": [
    "# Multi-Classification Machine Learning for Malware Analysis\n",
    "## 9 Types of Malware in this dataset:\n",
    "1. Ramnit         - RAT\n",
    "2. Lollipop       - Adware\n",
    "3. Kelihos_ver3   - RAT\n",
    "4. Vundo          - Adware\n",
    "5. Simda          - Botnet\n",
    "6. Tracur         - Malicious Browser Plugin\n",
    "7. Kelihos_ver1   - RAT\n",
    "8. Obfuscator.ACY - Obfuscates other malware/information\n",
    "9. Gatak          - RAT\n",
    "\n",
    "## Game Plan:\n",
    "\n",
    "- Look into creating more metrics to show off my model\n",
    "- Improve the way I import data for the model\n",
    "- Explain my code and solution in detail\n",
    "- Port into the main program/script\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529f870",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9678f78f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/eddy/.local/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/eddy/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/eddy/.local/lib/python3.10/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/eddy/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/eddy/.local/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/eddy/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/eddy/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/eddy/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/eddy/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/eddy/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/eddy/.local/lib/python3.10/site-packages (0.14.1)\n",
      "Requirement already satisfied: requests in /home/eddy/.local/lib/python3.10/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: torch==1.13.1 in /home/eddy/.local/lib/python3.10/site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/eddy/.local/lib/python3.10/site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: typing-extensions in /home/eddy/.local/lib/python3.10/site-packages (from torchvision) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/eddy/.local/lib/python3.10/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/eddy/.local/lib/python3.10/site-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/eddy/.local/lib/python3.10/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/eddy/.local/lib/python3.10/site-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (59.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/eddy/.local/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jupyterthemes in /home/eddy/.local/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/eddy/.local/lib/python3.10/site-packages (from jupyterthemes) (3.7.1)\n",
      "Requirement already satisfied: jupyter-core in /home/eddy/.local/lib/python3.10/site-packages (from jupyterthemes) (5.2.0)\n",
      "Requirement already satisfied: lesscpy>=0.11.2 in /home/eddy/.local/lib/python3.10/site-packages (from jupyterthemes) (0.15.1)\n",
      "Requirement already satisfied: ipython>=5.4.1 in /home/eddy/.local/lib/python3.10/site-packages (from jupyterthemes) (8.11.0)\n",
      "Requirement already satisfied: notebook>=5.6.0 in /home/eddy/.local/lib/python3.10/site-packages (from jupyterthemes) (6.5.3)\n",
      "Requirement already satisfied: pickleshare in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=5 in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (5.9.0)\n",
      "Requirement already satisfied: decorator in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (3.0.38)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (0.18.2)\n",
      "Requirement already satisfied: backcall in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/eddy/.local/lib/python3.10/site-packages (from ipython>=5.4.1->jupyterthemes) (2.14.0)\n",
      "Requirement already satisfied: ply in /home/eddy/.local/lib/python3.10/site-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (4.39.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eddy/.local/lib/python3.10/site-packages (from matplotlib>=1.4.3->jupyterthemes) (0.11.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (6.2)\n",
      "Requirement already satisfied: ipykernel in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (6.21.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (0.17.1)\n",
      "Requirement already satisfied: ipython-genutils in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (5.7.3)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (7.2.9)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (0.16.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (0.5.3)\n",
      "Requirement already satisfied: jinja2 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (3.1.2)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (8.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (25.0.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/eddy/.local/lib/python3.10/site-packages (from notebook>=5.6.0->jupyterthemes) (21.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-core->jupyterthemes) (3.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/eddy/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/eddy/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (2.4.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /home/eddy/.local/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.2.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.7.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.11.2)\n",
      "Requirement already satisfied: tinycss2 in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.2.2)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.0.5)\n",
      "Requirement already satisfied: defusedxml in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.7.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/lib/python3/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.0.1)\n",
      "Requirement already satisfied: bleach in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (6.0.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/eddy/.local/lib/python3.10/site-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/eddy/.local/lib/python3.10/site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.16.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/eddy/.local/lib/python3.10/site-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (4.17.3)\n",
      "Requirement already satisfied: wcwidth in /home/eddy/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.4.1->jupyterthemes) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->jupyterthemes) (1.16.0)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->notebook>=5.6.0->jupyterthemes) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/eddy/.local/lib/python3.10/site-packages (from argon2-cffi->notebook>=5.6.0->jupyterthemes) (21.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/eddy/.local/lib/python3.10/site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (1.6.6)\n",
      "Requirement already satisfied: psutil in /home/eddy/.local/lib/python3.10/site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (5.9.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/eddy/.local/lib/python3.10/site-packages (from ipykernel->notebook>=5.6.0->jupyterthemes) (0.1.2)\n",
      "Requirement already satisfied: pure-eval in /home/eddy/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/eddy/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/eddy/.local/lib/python3.10/site-packages (from stack-data->ipython>=5.4.1->jupyterthemes) (1.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (22.2.0)\n",
      "Requirement already satisfied: websocket-client in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.6.2)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.4.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/eddy/.local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/eddy/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.4)\n",
      "Requirement already satisfied: webencodings in /home/eddy/.local/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/eddy/.local/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/eddy/.local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (2.21)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.1.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /home/eddy/.local/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.1.4)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/lib/python3/dist-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (5.4.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (2.3)\n",
      "Requirement already satisfied: isoduration in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (20.11.0)\n",
      "Requirement already satisfied: uri-template in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (1.2.0)\n",
      "Requirement already satisfied: fqdn in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (1.5.1)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/eddy/.local/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (1.12)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/eddy/.local/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install jupyterthemes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import shutil\n",
    "from pathlib import Path #Convert all directory accesses to this\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c088df",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9004337c",
   "metadata": {
    "code_folding": [
     0,
     3,
     9,
     14,
     18,
     22,
     25,
     30,
     38,
     44,
     51,
     57,
     65,
     68,
     74,
     84,
     90
    ]
   },
   "outputs": [],
   "source": [
    "def listFilesInDirectory(directoryContainingFiles):\n",
    "    return glob.glob(directoryContainingFiles) \n",
    "\n",
    "def stripFilePathAndExtension(filePath, prefixToStrip, suffixToStrip):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    #return filePath\n",
    "    return Path(filePath).stem\n",
    "\n",
    "def replaceFilePathAndExtension(filePath, prefixToStrip, prefixToInsert, suffixToStrip, suffixToInsert):\n",
    "    filePath = filePath.replace(prefixToStrip, prefixToInsert)\n",
    "    filePath = filePath.replace(suffixToStrip, suffixToInsert)\n",
    "    return filePath\n",
    "\n",
    "def printDataFrame(dataframe):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(dataframe)\n",
    "\n",
    "def zeroOutDataframe(dataframe):\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    return dataframe\n",
    "\n",
    "def countEntriesInDataframe(dataframe):\n",
    "    return np.count_nonzero(dataframe)\n",
    "\n",
    "def sortDictionary(dictionary):\n",
    "    returnVal = sorted(dict(Counter(dictionary)).items(), key=lambda kv:\n",
    "                 (kv[1], kv[0]))\n",
    "    return returnVal\n",
    "\n",
    "def fileNewlineIntoList(filePath):\n",
    "    lineList = []\n",
    "    with open(filePath) as openFile:\n",
    "        for line in openFile:\n",
    "            temp = line.strip()\n",
    "            lineList.append(temp)\n",
    "    return lineList\n",
    "\n",
    "def stripNewlineAndWhitespace(textStringToStrip):\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\t\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\n\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\" \",\"\")\n",
    "    return textStringToStrip\n",
    "\n",
    "def stripNewlineAndWhitespaceFromList(listToStrip):\n",
    "    for i in range(0,len(listToStrip)):\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\t\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\n\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\" \",\"\")\n",
    "    return listToStrip\n",
    "\n",
    "def regexSearchFile(filePath, regexPattern):\n",
    "    with open(filePath) as openFile:\n",
    "        matches = re.findall(regexPattern, openFile.read())\n",
    "    openFile.close()\n",
    "    return matches\n",
    "\n",
    "def cleanFileNameList(fileNameList,malwareClass):\n",
    "    filePathToNameDict = {}\n",
    "    for i in range(0, len(fileNameList)): \n",
    "        strippedFile = stripFilePathAndExtension(fileNameList[i], \"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(malwareClass)+\"/\", \".asm\") #FIX THIS TO ALLOW FOR DIFFERENT CLASSES\n",
    "        filePathToNameDict[strippedFile] = fileNameList[i]\n",
    "        fileNameList[i] = strippedFile\n",
    "    return fileNameList\n",
    "\n",
    "def generateClassDataFrame(instructionList,fileNameListForClass):\n",
    "    return zeroOutDataframe(pd.DataFrame(columns=instructionList,index=fileNameListForClass))\n",
    "\n",
    "def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Old and working before I tried the next version\n",
    "#    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "#    for file in backupFileList: # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "#        fileClean = stripFilePathAndExtension(file,\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "#        shutil.copyfile(file,\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "#        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "#def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Experimental\n",
    "    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "    for fileIndex in range(0,len(backupFileList)): # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "        fileClean = stripFilePathAndExtension(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "        try:\n",
    "            shutil.copyfile(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        except:\n",
    "            fileIndex = fileIndex + 1\n",
    "        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "\n",
    "def generateFilenameToDirectoryDict(fileDirectory):\n",
    "    filePathToNameDict = {}\n",
    "    for file in fileDirectory:\n",
    "        filePathToNameDict[Path(file).stem] = file\n",
    "    return filePathToNameDict\n",
    "\n",
    "def populateMalwareDataframe(fileDirectoryTopLevel,instructionList):\n",
    "\n",
    "    filePathToNameDict = generateFilenameToDirectoryDict(listFilesInDirectory(fileDirectoryTopLevel))\n",
    "    dataFrame = zeroOutDataframe(pd.DataFrame(columns=instructionList,index=filePathToNameDict.keys()))\n",
    "\n",
    "    for file in filePathToNameDict.keys(): # Go through every file in our directory\n",
    "        fileDirectory = filePathToNameDict[file] # Convert using dict here\n",
    "        instructionsForThisFile = stripNewlineAndWhitespaceFromList(regexSearchFile(fileDirectory,\"(?:\\t{3,7}       (?!db|dd)[a-zA-Z]{2,6} {1,})\")) # cleaning and pulling instructions\n",
    "\n",
    "        pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up   \n",
    "        for i in range(0, len(pandasSeriesTest[0])):\n",
    "            dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
    "        \n",
    "        #Optional cleaning options for my DF to merge dupe columns and group them up\n",
    "        dataFrame = dataFrame.groupby(axis=1, level=0).sum() # Merges dupe columns\n",
    "        #dataFrame = dataFrame.loc[:, (dataFrame != 0).any(axis=0)] # Removes columns with no values\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c1528",
   "metadata": {},
   "source": [
    "## Pulling the files from the dataset into the class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95d8cd72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "#moveFilesToClassFolders(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/*\"),pd.read_csv(\"/home/eddy/machine-learning/data/trainLabels.csv\"))\n",
    "#moveFilesToClassFolders(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subsetBackup/*\"),pd.read_csv(\"/home/eddy/machine-learning/data/trainLabels.csv\"))\n",
    "print(len(glob.glob(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52e08e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "187\n",
      "196\n",
      "196\n",
      "194\n",
      "194\n",
      "178\n",
      "178\n",
      "84\n",
      "84\n",
      "180\n",
      "180\n",
      "170\n",
      "170\n",
      "185\n",
      "185\n",
      "179\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "testDirList = [\"/home/eddy/machine-learning/data/dataset-subset/class-1/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-2/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-3/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-4/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-5/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-6/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-7/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-8/*\",\"/home/eddy/machine-learning/data/dataset-subset/class-9/*\"]\n",
    "for directory in testDirList:\n",
    "    fileList = glob.glob(directory)\n",
    "    print(len(fileList))\n",
    "    for i in range(0,len(fileList)):\n",
    "        if(i >= 100):\n",
    "            os.remove(fileList[i])\n",
    "    print(len(fileList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08339e72",
   "metadata": {},
   "source": [
    "## Creating the Pandas DataFrame for the malware classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f48d380",
   "metadata": {
    "code_folding": [
     10,
     23,
     35,
     47,
     59,
     71,
     83,
     95,
     107
    ],
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 657871: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m instructionList \u001b[39m=\u001b[39m [instruction\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m instruction \u001b[39min\u001b[39;00m instructionList] \u001b[39m# Making all instructions lowercase\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dataframeClassOne \u001b[39m=\u001b[39m generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\u001b[39m\"\u001b[39m\u001b[39m/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm*\u001b[39m\u001b[39m\"\u001b[39m),\u001b[39m1\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m dataframeClassOne \u001b[39m=\u001b[39m populateMalwareDataframe(\u001b[39m\"\u001b[39;49m\u001b[39m/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\u001b[39;49m\u001b[39m\"\u001b[39;49m,instructionList)\n\u001b[1;32m      6\u001b[0m dataframeClassOne\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m/home/eddy/machine-learning/data/datasetClassOne.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m#dataframeClassOne = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[86], line 98\u001b[0m, in \u001b[0;36mpopulateMalwareDataframe\u001b[0;34m(fileDirectoryTopLevel, instructionList)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m filePathToNameDict\u001b[39m.\u001b[39mkeys(): \u001b[39m# Go through every file in our directory\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     fileDirectory \u001b[39m=\u001b[39m filePathToNameDict[file] \u001b[39m# Convert using dict here\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     instructionsForThisFile \u001b[39m=\u001b[39m stripNewlineAndWhitespaceFromList(regexSearchFile(fileDirectory,\u001b[39m\"\u001b[39;49m\u001b[39m(?:\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m{\u001b[39;49m\u001b[39m3,7}       (?!db|dd)[a-zA-Z]\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m2,6} \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m1,})\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39m# cleaning and pulling instructions\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     pandasSeriesTest \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(instructionsForThisFile)\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mindex, pd\u001b[39m.\u001b[39mSeries(instructionsForThisFile)\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mvalues \u001b[39m# Counting each instruction up   \u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(pandasSeriesTest[\u001b[39m0\u001b[39m])):\n",
      "Cell \u001b[0;32mIn[86], line 54\u001b[0m, in \u001b[0;36mregexSearchFile\u001b[0;34m(filePath, regexPattern)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregexSearchFile\u001b[39m(filePath, regexPattern):\n\u001b[1;32m     53\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filePath) \u001b[39mas\u001b[39;00m openFile:\n\u001b[0;32m---> 54\u001b[0m         matches \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(regexPattern, openFile\u001b[39m.\u001b[39;49mread())\n\u001b[1;32m     55\u001b[0m     openFile\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m matches\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc3 in position 657871: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "instructionList = fileNewlineIntoList(\"/home/eddy/machine-learning/instructionListComplete.txt\")\n",
    "instructionList = [instruction.lower() for instruction in instructionList] # Making all instructions lowercase\n",
    "\n",
    "dataframeClassOne = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm*\"),1))\n",
    "dataframeClassOne = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\",instructionList)\n",
    "dataframeClassOne.to_csv(\"/home/eddy/machine-learning/data/datasetClassOne.csv\")\n",
    "#dataframeClassOne = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "dataframeClassOne = zeroOutDataframe(dataframeClassOne)\n",
    "dataframeClassOne.loc[~(dataframeClassOne==0).all(axis=1)]\n",
    "dataframeClassOne.insert(0,\"class\",1)\n",
    "#dataframeClassOneNormalised = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "#dataframeClassOneNormalised = zeroOutDataframe(dataframeClassOneNormalised)\n",
    "#dataframeClassOneNormalised.loc[~(dataframeClassOneNormalised==0).all(axis=1)]\n",
    "#dataframeClassOneNormalised.insert(0,\"class\",1)\n",
    "\n",
    "\n",
    "dataframeClassTwo = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm*\"),2))\n",
    "dataframeClassTwo = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm\",instructionList)\n",
    "dataframeClassTwo.to_csv(\"/home/eddy/machine-learning/data/datasetClassTwo.csv\")\n",
    "#dataframeClassTwo = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "dataframeClassTwo = zeroOutDataframe(dataframeClassTwo)\n",
    "dataframeClassTwo.loc[~(dataframeClassTwo==0).all(axis=1)]\n",
    "dataframeClassTwo.insert(0,\"class\",2)\n",
    "#dataframeClassTwoNormalised = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "#dataframeClassTwoNormalised = zeroOutDataframe(dataframeClassTwoNormalised)\n",
    "#dataframeClassTwoNormalised.loc[~(dataframeClassTwoNormalised==0).all(axis=1)]\n",
    "#dataframeClassTwoNormalised.insert(0,\"class\",2)\n",
    "\n",
    "dataframeClassThree = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm*\"),3))\n",
    "dataframeClassThree = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm\",instructionList)\n",
    "dataframeClassThree.to_csv(\"/home/eddy/machine-learning/data/datasetClassThree.csv\")\n",
    "#dataframeClassThree = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "dataframeClassThree = zeroOutDataframe(dataframeClassThree)\n",
    "dataframeClassThree.loc[~(dataframeClassThree==0).all(axis=1)]\n",
    "dataframeClassThree.insert(0,\"class\",3)\n",
    "#dataframeClassThreeNormalised = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "#dataframeClassThreeNormalised = zeroOutDataframe(dataframeClassThreeNormalised)\n",
    "#dataframeClassThreeNormalised.loc[~(dataframeClassThreeNormalised==0).all(axis=1)]\n",
    "#dataframeClassThreeNormalised.insert(0,\"class\",3)\n",
    "\n",
    "dataframeClassFour = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm*\"),4))\n",
    "dataframeClassFour = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm\",instructionList)\n",
    "dataframeClassFour.to_csv(\"/home/eddy/machine-learning/data/datasetClassFour.csv\")\n",
    "#dataframeClassFour = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "dataframeClassFour= zeroOutDataframe(dataframeClassFour)\n",
    "dataframeClassFour.loc[~(dataframeClassFour==0).all(axis=1)]\n",
    "dataframeClassFour.insert(0,\"class\",4)\n",
    "#dataframeClassFourNormalised = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "#dataframeClassFourNormalised= zeroOutDataframe(dataframeClassFourNormalised)\n",
    "#dataframeClassFourNormalised.loc[~(dataframeClassFourNormalised==0).all(axis=1)]\n",
    "#dataframeClassFourNormalised.insert(0,\"class\",4)\n",
    "\n",
    "dataframeClassFive = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm*\"),5))\n",
    "dataframeClassFive = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm\",instructionList)\n",
    "dataframeClassFive.to_csv(\"/home/eddy/machine-learning/data/datasetClassFive.csv\")\n",
    "#dataframeClassFive = dataframeClassFive.div(dataframeClassFive.sum(axis=1), axis=0)\n",
    "dataframeClassFive = zeroOutDataframe(dataframeClassFive)\n",
    "dataframeClassFive.loc[~(dataframeClassFive==0).all(axis=1)]\n",
    "dataframeClassFive.insert(0,\"class\",5)\n",
    "#dataframeClassFiveNormalised = zeroOutDataframe(dataframeClassFiveNormalised)\n",
    "#dataframeClassFiveNormalised.loc[~(dataframeClassFiveNormalised==0).all(axis=1)]\n",
    "#dataframeClassFiveNormalised.to_csv(\"/home/eddy/machine-learning/data/datasetClassFiveNormalised.csv\")\n",
    "#dataframeClassFiveNormalised.insert(0,\"class\",5)\n",
    "\n",
    "dataframeClassSix = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm*\"),6))\n",
    "dataframeClassSix = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm\",instructionList)\n",
    "dataframeClassSix.to_csv(\"/home/eddy/machine-learning/data/datasetClassSix.csv\")\n",
    "#dataframeClassSix = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "dataframeClassSix = zeroOutDataframe(dataframeClassSix)\n",
    "dataframeClassSix.loc[~(dataframeClassSix==0).all(axis=1)]\n",
    "dataframeClassSix.insert(0,\"class\",6)\n",
    "#dataframeClassSixNormalised = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "#dataframeClassSixNormalised = zeroOutDataframe(dataframeClassSixNormalised)\n",
    "#dataframeClassSixNormalised.loc[~(dataframeClassSixNormalised==0).all(axis=1)]\n",
    "#dataframeClassSixNormalised.insert(0,\"class\",6)\n",
    "\n",
    "dataframeClassSeven = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm*\"),7))\n",
    "dataframeClassSeven = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm\",instructionList)\n",
    "dataframeClassSeven.to_csv(\"/home/eddy/machine-learning/data/datasetClassSeven.csv\")\n",
    "#dataframeClassSeven = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "dataframeClassSeven = zeroOutDataframe(dataframeClassSeven)\n",
    "dataframeClassSeven.loc[~(dataframeClassSeven==0).all(axis=1)]\n",
    "dataframeClassSeven.insert(0,\"class\",7)\n",
    "#dataframeClassSevenNormalised = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "#dataframeClassSevenNormalised = zeroOutDataframe(dataframeClassSevenNormalised)\n",
    "#dataframeClassSevenNormalised.loc[~(dataframeClassSevenNormalised==0).all(axis=1)]\n",
    "#dataframeClassSevenNormalised.insert(0,\"class\",7)\n",
    "\n",
    "dataframeClassEight = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm*\"),8))\n",
    "dataframeClassEight = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm\",instructionList)\n",
    "dataframeClassEight.to_csv(\"/home/eddy/machine-learning/data/datasetClassEight.csv\")\n",
    "#dataframeClassEight = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "dataframeClassEight = zeroOutDataframe(dataframeClassEight)\n",
    "dataframeClassEight.loc[~(dataframeClassEight==0).all(axis=1)]\n",
    "dataframeClassEight.insert(0,\"class\",8)\n",
    "#dataframeClassEightNormalised = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "#dataframeClassEightNormalised = zeroOutDataframe(dataframeClassEightNormalised)\n",
    "#dataframeClassEightNormalised.loc[~(dataframeClassEightNormalised==0).all(axis=1)]\n",
    "#dataframeClassEightNormalised.insert(0,\"class\",8)\n",
    "\n",
    "dataframeClassNine = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm*\"),9))\n",
    "dataframeClassNine = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm\",instructionList)\n",
    "dataframeClassNine.to_csv(\"/home/eddy/machine-learning/data/datasetClassNine.csv\")\n",
    "#dataframeClassNine = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "dataframeClassNine = zeroOutDataframe(dataframeClassNine)\n",
    "dataframeClassNine.loc[~(dataframeClassNine==0).all(axis=1)]\n",
    "dataframeClassNine.insert(0,\"class\",9)\n",
    "#dataframeClassNineNormalised = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "#dataframeClassNineNormalised = zeroOutDataframe(dataframeClassNineNormalised)\n",
    "#dataframeClassNineNormalised.loc[~(dataframeClassNineNormalised==0).all(axis=1)]\n",
    "#dataframeClassNineNormalised.insert(0,\"class\",9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd53ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframesNormalisedList = [dataframeClassOneNormalised,dataframeClassTwoNormalised,dataframeClassThreeNormalised,dataframeClassFourNormalised,dataframeClassFiveNormalised,dataframeClassSixNormalised,dataframeClassSevenNormalised,dataframeClassEightNormalised,dataframeClassNineNormalised]\n",
    "dataframesList = [dataframeClassOne,dataframeClassTwo,dataframeClassThree,dataframeClassFour,dataframeClassFive,dataframeClassSix,dataframeClassSeven,dataframeClassEight,dataframeClassNine]\n",
    "finalDF = pd.concat(dataframesList).drop_duplicates()\n",
    "#finalDF = finalDF.drop([\"assume\",\"align\"],axis=1) # Error, seems like they're gone already\n",
    "finalDF = zeroOutDataframe(finalDF)\n",
    "finalDF.loc[~(finalDF==0).all(axis=1)]\n",
    "finalDF = finalDF.loc[:, (finalDF != 0).any(axis=0)] # Removes columns with no values\n",
    "finalDF = finalDF.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e5ba3",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing sklearn and getting basic info about my training set\n",
    "#Merge all data into one DF with labels intact\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "finalDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09a03b",
   "metadata": {},
   "source": [
    "## Splitting the data into train+test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3795c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing up the dataset into train, validate and test sets\n",
    "trainDF, testAndValidDF = train_test_split(finalDF, test_size=0.4)\n",
    "testDF, validDF = train_test_split(testAndValidDF, test_size=0.5)\n",
    "\n",
    "print(f\"Training Dataset rows and columns: {trainDF.shape}\")\n",
    "print(f\"Test Dataset rows and columns: {testDF.shape}\")\n",
    "print(f\"Validation Dataset rows and columns: {validDF.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cda6a",
   "metadata": {},
   "source": [
    "## Training Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "#not doing sns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training stats based on the trainDF dataset\n",
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "trainStats = trainStats.transpose()\n",
    "trainStats.to_csv(\"/home/eddy/traindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae27eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "trainLabels = trainDF.pop(\"class\")\n",
    "testLabels = testDF.pop(\"class\")\n",
    "validLabels = validDF.pop(\"class\")\n",
    "\n",
    "print(len(trainLabels))\n",
    "print(len(testLabels))\n",
    "print(len(validLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d56d5",
   "metadata": {},
   "source": [
    "## Data Normalisation/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(data):\n",
    "    #return (data -trainStats[\"mean\"]) / trainStats['std'] #Works fine, experimenting with the OTHER\n",
    "    return data\n",
    "    #return data.div(data.sum(axis=1), axis=0)\n",
    "\n",
    "normalisedTrainDF = normaliseData(trainDF)\n",
    "normalisedTestDF = normaliseData(testDF)\n",
    "normalisedValidDF = normaliseData(validDF)\n",
    "\n",
    "normalisedTrainDF = normalisedTrainDF.replace(np.nan,0)\n",
    "normalisedTestDF = normalisedTestDF.replace(np.nan,0)\n",
    "normalisedValidDF = normalisedValidDF.replace(np.nan,0)\n",
    "normalisedTrainDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f80820",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "model = svm.SVC(C = 1.5,\n",
    "                kernel='linear')\n",
    "modelPoly = svm.SVC(C = 1.5,\n",
    "                   kernel='poly')\n",
    "modelRBF = svm.SVC(C = 1.5,\n",
    "                   kernel='rbf')\n",
    "modelSig = svm.SVC(C = 1.5,\n",
    "                   kernel='sigmoid')\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(normalisedTrainDF, trainLabels)\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(normalisedTrainDF)\n",
    "\n",
    "modelPoly.fit(normalisedTrainDF, trainLabels)\n",
    "y_predPoly = modelPoly.predict(normalisedTrainDF)\n",
    "\n",
    "modelRBF.fit(normalisedTrainDF, trainLabels)\n",
    "y_predRBF = modelRBF.predict(normalisedTrainDF)\n",
    "\n",
    "modelSig.fit(normalisedTrainDF, trainLabels)\n",
    "y_predSig = modelSig.predict(normalisedTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleBatch = normalisedTestDF[:10]\n",
    "\n",
    "exampleResult = model.predict(exampleBatch)\n",
    "\n",
    "print(pd.Series(list(exampleBatch.index),index=exampleResult).to_string())\n",
    "print(f\"Predicted values: {exampleResult}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426cde3",
   "metadata": {},
   "source": [
    "## Checking how training went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#print(normalisedTrainDF.shape)\n",
    "normalisedTrainDF = normalisedTrainDF[np.isfinite(normalisedTrainDF).all(1)]\n",
    "#print(normalisedTrainDF.shape)\n",
    "\n",
    "#print(len(y_pred))\n",
    "#y_pred = model.predict(normalisedTrainDF)\n",
    "print(\"Linear Train Accuracy: \",metrics.accuracy_score(trainLabels,y_pred))\n",
    "print(\"Poly Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predPoly))\n",
    "print(\"RBF Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predRBF))\n",
    "print(\"Sigmoid Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predSig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34661fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#newNormalisedValidDF = zeroOutDataframe(normalisedValidDF)\n",
    "#newNormalisedValidDF = newNormalisedValidDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "y_pred = model.predict(normalisedValidDF)\n",
    "print(\"Linear Valid Accuracy: \",metrics.accuracy_score(validLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newNormalisedTestDF = zeroOutDataframe(normalisedTestDF)\n",
    "#newNormalisedTestDF = newNormalisedTestDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "y_pred = model.predict(normalisedTestDF)\n",
    "print(\"Test Accuracy: \",metrics.accuracy_score(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "predictResults = model.predict(normalisedTestDF)\n",
    "cm = confusion_matrix(predictResults,predictResults)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix - Linear\")\n",
    "ax.set_xticks([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax=ax, yticklabels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"], xticklabels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]); #Semicolon removes the annoying text above the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutationImportance = permutation_importance(model, normalisedTrainDF, trainLabels)\n",
    "featuresList = np.array(list(normalisedTrainDF.columns))\n",
    "sortedIDX = permutationImportance.importances_mean.argsort()\n",
    "mostImportantIndexesPermutation = [list(permutationImportance.importances_mean[sortedIDX]).index(i) for i in heapq.nlargest(30, permutationImportance.importances_mean[sortedIDX])]\n",
    "\n",
    "### Showing the largest features\n",
    "newFeaturesList = []\n",
    "newPermutationImportanceList = []\n",
    "\n",
    "for i in mostImportantIndexesPermutation[::-1]:\n",
    "    newFeaturesList.append(featuresList[sortedIDX][i])\n",
    "    newPermutationImportanceList.append(permutationImportance.importances_mean[sortedIDX][i])\n",
    "\n",
    "occurancesQuantity={}\n",
    "for i in newFeaturesList[::-1]:\n",
    "    occurancesQuantity.update({i:str(int(finalDF[i].mean()))})\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(newFeaturesList, newPermutationImportanceList);\n",
    "plt.xlabel(\"Permutation Importance/Feature\");\n",
    "plt.margins(x=0)\n",
    "plt.xticks([0,0.1,0.2,0.3,0.4,0.5],[\"0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1\"])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(list(occurancesQuantity.keys())[::-1], preprocessing.minmax_scale(list(occurancesQuantity.values())[::-1],feature_range=(0,0.5)));\n",
    "plt.xlabel(\"Mean Relative occurances/Feature\");\n",
    "plt.xticks([0,0.1,0.2,0.3,0.4,0.5],[\"0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1\"])\n",
    "plt.margins(x=0)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testLabels,y_pred,output_dict=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
