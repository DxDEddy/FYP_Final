{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c8a04b",
   "metadata": {},
   "source": [
    "# Multi-Classification Machine Learning for Malware Analysis\n",
    "## 9 Types of Malware in this dataset:\n",
    "1. Ramnit         - RAT\n",
    "2. Lollipop       - Adware\n",
    "3. Kelihos_ver3   - RAT\n",
    "4. Vundo          - Adware\n",
    "5. Simda          - Botnet\n",
    "6. Tracur         - Malicious Browser Plugin\n",
    "7. Kelihos_ver1   - RAT\n",
    "8. Obfuscator.ACY - Obfuscates other malware/information\n",
    "9. Gatak          - RAT\n",
    "\n",
    "## Game Plan:\n",
    "\n",
    "- Look into creating more metrics to show off my model\n",
    "- Improve the way I import data for the model\n",
    "- Explain my code and solution in detail\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529f870",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9678f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install jupyter-resource-usage\n",
    "!{sys.executable} -m pip install jupyterthemes\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import shutil\n",
    "from pathlib import Path #Convert all directory accesses to this\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c088df",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9004337c",
   "metadata": {
    "code_folding": [
     0,
     3,
     9,
     14,
     18,
     22,
     25,
     30,
     38,
     44,
     51,
     57,
     65,
     68,
     74,
     84,
     90
    ]
   },
   "outputs": [],
   "source": [
    "def listFilesInDirectory(directoryContainingFiles):\n",
    "    return glob.glob(directoryContainingFiles) \n",
    "\n",
    "def stripFilePathAndExtension(filePath, prefixToStrip, suffixToStrip):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    #return filePath\n",
    "    return Path(filePath).stem\n",
    "\n",
    "def replaceFilePathAndExtension(filePath, prefixToStrip, prefixToInsert, suffixToStrip, suffixToInsert):\n",
    "    filePath = filePath.replace(prefixToStrip, \"\")\n",
    "    filePath = filePath.replace(suffixToStrip, \"\")\n",
    "    return filePath\n",
    "\n",
    "def printDataFrame(dataframe):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(dataframe)\n",
    "\n",
    "def zeroOutDataframe(dataframe):\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    return dataframe\n",
    "\n",
    "def countEntriesInDataframe(dataframe):\n",
    "    return np.count_nonzero(dataframe)\n",
    "\n",
    "def sortDictionary(dictionary):\n",
    "    returnVal = sorted(dict(Counter(dictionary)).items(), key=lambda kv:\n",
    "                 (kv[1], kv[0]))\n",
    "    return returnVal\n",
    "\n",
    "def fileNewlineIntoList(filePath):\n",
    "    lineList = []\n",
    "    with open(filePath) as openFile:\n",
    "        for line in openFile:\n",
    "            temp = line.strip()\n",
    "            lineList.append(temp)\n",
    "    return lineList\n",
    "\n",
    "def stripNewlineAndWhitespace(textStringToStrip):\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\t\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\"\\n\",\"\")\n",
    "    textStringToStrip = textStringToStrip.replace(\" \",\"\")\n",
    "    return textStringToStrip\n",
    "\n",
    "def stripNewlineAndWhitespaceFromList(listToStrip):\n",
    "    for i in range(0,len(listToStrip)):\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\t\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\"\\n\",\"\")\n",
    "        listToStrip[i] = listToStrip[i].replace(\" \",\"\")\n",
    "    return listToStrip\n",
    "\n",
    "def regexSearchFile(filePath, regexPattern):\n",
    "    with open(filePath) as openFile:\n",
    "        matches = re.findall(regexPattern, openFile.read())\n",
    "    openFile.close()\n",
    "    return matches\n",
    "\n",
    "def cleanFileNameList(fileNameList,malwareClass):\n",
    "    filePathToNameDict = {}\n",
    "    for i in range(0, len(fileNameList)): \n",
    "        strippedFile = stripFilePathAndExtension(fileNameList[i], \"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(malwareClass)+\"/\", \".asm\") #FIX THIS TO ALLOW FOR DIFFERENT CLASSES\n",
    "        filePathToNameDict[strippedFile] = fileNameList[i]\n",
    "        fileNameList[i] = strippedFile\n",
    "    return fileNameList\n",
    "\n",
    "def generateClassDataFrame(instructionList,fileNameListForClass):\n",
    "    return zeroOutDataframe(pd.DataFrame(columns=instructionList,index=fileNameListForClass))\n",
    "\n",
    "def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Old and working before I tried the next version\n",
    "    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "    for file in backupFileList: # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "        fileClean = stripFilePathAndExtension(file,\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "        shutil.copyfile(file,\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "#def moveFilesToClassFolders(backupFileList, fullFileNamesListFromCSV): #Experimental\n",
    "    fullFileNamesListFromCSV.set_index(\"Id\",inplace=True)\n",
    "    for fileIndex in range(0,len(backupFileList)): # file is the full path to the file, fileClean is just the name of the file without extension\n",
    "        fileClean = stripFilePathAndExtension(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/\",\".asm\")\n",
    "        try:\n",
    "            shutil.copyfile(backupFileList[fileIndex],\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "        except:\n",
    "            fileIndex = fileIndex + 1\n",
    "        #print(\"from: \"+file+\" ------------- to: \"+\"/home/eddy/machine-learning/data/dataset-subset/class-\"+str(fullFileNamesListFromCSV.loc[fileClean,\"Class\"])+\"/\"+str(fullFileNamesListFromCSV.loc[fileClean].name)+\".asm\")\n",
    "\n",
    "def generateFilenameToDirectoryDict(fileDirectory):\n",
    "    filePathToNameDict = {}\n",
    "    for file in fileDirectory:\n",
    "        filePathToNameDict[Path(file).stem] = file\n",
    "    return filePathToNameDict\n",
    "\n",
    "def populateMalwareDataframe(fileDirectoryTopLevel,instructionList):\n",
    "\n",
    "    filePathToNameDict = generateFilenameToDirectoryDict(listFilesInDirectory(fileDirectoryTopLevel))\n",
    "    dataFrame = zeroOutDataframe(pd.DataFrame(columns=instructionList,index=filePathToNameDict.keys()))\n",
    "\n",
    "    for file in filePathToNameDict.keys(): # Go through every file in our directory\n",
    "        fileDirectory = filePathToNameDict[file] # Convert using dict here\n",
    "        instructionsForThisFile = stripNewlineAndWhitespaceFromList(regexSearchFile(fileDirectory,\"(?:\\t{3,7}       (?!db|dd)[a-zA-Z]{2,6} {1,})\")) # cleaning and pulling instructions\n",
    "\n",
    "        pandasSeriesTest = pd.Series(instructionsForThisFile).value_counts().index, pd.Series(instructionsForThisFile).value_counts().values # Counting each instruction up   \n",
    "        for i in range(0, len(pandasSeriesTest[0])):\n",
    "            dataFrame.loc[file,pandasSeriesTest[0][i]] = pandasSeriesTest[1][i]  #0 = instruction and 1 = count columns ||| Second value is index within that column\n",
    "        \n",
    "        #Optional cleaning options for my DF to merge dupe columns and group them up\n",
    "        dataFrame = dataFrame.groupby(axis=1, level=0).sum() # Merges dupe columns\n",
    "        #dataFrame = dataFrame.loc[:, (dataFrame != 0).any(axis=0)] # Removes columns with no values\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c1528",
   "metadata": {},
   "source": [
    "## Pulling the files from the dataset into the class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d8cd72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#moveFilesToClassFolders(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subsetFullInitialSubset/*\"),pd.read_csv(\"/home/eddy/machine-learning/data/trainLabels.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08339e72",
   "metadata": {},
   "source": [
    "## Creating the Pandas DataFrame for the malware classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48d380",
   "metadata": {
    "code_folding": [
     10,
     23,
     35,
     47,
     59,
     71,
     83,
     95,
     107
    ],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructionList = fileNewlineIntoList(\"/home/eddy/machine-learning/instructionListComplete.txt\")\n",
    "instructionList = [instruction.lower() for instruction in instructionList] # Making all instructions lowercase\n",
    "\n",
    "dataframeClassOne = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\"),1))\n",
    "dataframeClassOne = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-1/*.asm\",instructionList)\n",
    "dataframeClassOne.to_csv(\"/home/eddy/machine-learning/data/datasetClassOne.csv\")\n",
    "#dataframeClassOne = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "dataframeClassOne = zeroOutDataframe(dataframeClassOne)\n",
    "dataframeClassOne.loc[~(dataframeClassOne==0).all(axis=1)]\n",
    "dataframeClassOne.insert(0,\"class\",1)\n",
    "#dataframeClassOneNormalised = dataframeClassOne.div(dataframeClassOne.sum(axis=1), axis=0)\n",
    "#dataframeClassOneNormalised = zeroOutDataframe(dataframeClassOneNormalised)\n",
    "#dataframeClassOneNormalised.loc[~(dataframeClassOneNormalised==0).all(axis=1)]\n",
    "#dataframeClassOneNormalised.insert(0,\"class\",1)\n",
    "\n",
    "\n",
    "dataframeClassTwo = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm\"),2))\n",
    "dataframeClassTwo = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-2/*.asm\",instructionList)\n",
    "dataframeClassTwo.to_csv(\"/home/eddy/machine-learning/data/datasetClassTwo.csv\")\n",
    "#dataframeClassTwo = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "dataframeClassTwo = zeroOutDataframe(dataframeClassTwo)\n",
    "dataframeClassTwo.loc[~(dataframeClassTwo==0).all(axis=1)]\n",
    "dataframeClassTwo.insert(0,\"class\",2)\n",
    "#dataframeClassTwoNormalised = dataframeClassTwo.div(dataframeClassTwo.sum(axis=1), axis=0)\n",
    "#dataframeClassTwoNormalised = zeroOutDataframe(dataframeClassTwoNormalised)\n",
    "#dataframeClassTwoNormalised.loc[~(dataframeClassTwoNormalised==0).all(axis=1)]\n",
    "#dataframeClassTwoNormalised.insert(0,\"class\",2)\n",
    "\n",
    "dataframeClassThree = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm\"),3))\n",
    "dataframeClassThree = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-3/*.asm\",instructionList)\n",
    "dataframeClassThree.to_csv(\"/home/eddy/machine-learning/data/datasetClassThree.csv\")\n",
    "#dataframeClassThree = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "dataframeClassThree = zeroOutDataframe(dataframeClassThree)\n",
    "dataframeClassThree.loc[~(dataframeClassThree==0).all(axis=1)]\n",
    "dataframeClassThree.insert(0,\"class\",3)\n",
    "#dataframeClassThreeNormalised = dataframeClassThree.div(dataframeClassThree.sum(axis=1), axis=0)\n",
    "#dataframeClassThreeNormalised = zeroOutDataframe(dataframeClassThreeNormalised)\n",
    "#dataframeClassThreeNormalised.loc[~(dataframeClassThreeNormalised==0).all(axis=1)]\n",
    "#dataframeClassThreeNormalised.insert(0,\"class\",3)\n",
    "\n",
    "dataframeClassFour = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm\"),4))\n",
    "dataframeClassFour = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-4/*.asm\",instructionList)\n",
    "dataframeClassFour.to_csv(\"/home/eddy/machine-learning/data/datasetClassFour.csv\")\n",
    "#dataframeClassFour = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "dataframeClassFour= zeroOutDataframe(dataframeClassFour)\n",
    "dataframeClassFour.loc[~(dataframeClassFour==0).all(axis=1)]\n",
    "dataframeClassFour.insert(0,\"class\",4)\n",
    "#dataframeClassFourNormalised = dataframeClassFour.div(dataframeClassFour.sum(axis=1), axis=0)\n",
    "#dataframeClassFourNormalised= zeroOutDataframe(dataframeClassFourNormalised)\n",
    "#dataframeClassFourNormalised.loc[~(dataframeClassFourNormalised==0).all(axis=1)]\n",
    "#dataframeClassFourNormalised.insert(0,\"class\",4)\n",
    "\n",
    "dataframeClassFive = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm\"),5))\n",
    "dataframeClassFive = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-5/*.asm\",instructionList)\n",
    "dataframeClassFive.to_csv(\"/home/eddy/machine-learning/data/datasetClassFive.csv\")\n",
    "#dataframeClassFive = dataframeClassFive.div(dataframeClassFive.sum(axis=1), axis=0)\n",
    "dataframeClassFive = zeroOutDataframe(dataframeClassFive)\n",
    "dataframeClassFive.loc[~(dataframeClassFive==0).all(axis=1)]\n",
    "dataframeClassFive.insert(0,\"class\",5)\n",
    "#dataframeClassFiveNormalised = zeroOutDataframe(dataframeClassFiveNormalised)\n",
    "#dataframeClassFiveNormalised.loc[~(dataframeClassFiveNormalised==0).all(axis=1)]\n",
    "#dataframeClassFiveNormalised.to_csv(\"/home/eddy/machine-learning/data/datasetClassFiveNormalised.csv\")\n",
    "#dataframeClassFiveNormalised.insert(0,\"class\",5)\n",
    "\n",
    "dataframeClassSix = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm\"),6))\n",
    "dataframeClassSix = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-6/*.asm\",instructionList)\n",
    "dataframeClassSix.to_csv(\"/home/eddy/machine-learning/data/datasetClassSix.csv\")\n",
    "#dataframeClassSix = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "dataframeClassSix = zeroOutDataframe(dataframeClassSix)\n",
    "dataframeClassSix.loc[~(dataframeClassSix==0).all(axis=1)]\n",
    "dataframeClassSix.insert(0,\"class\",6)\n",
    "#dataframeClassSixNormalised = dataframeClassSix.div(dataframeClassSix.sum(axis=1), axis=0)\n",
    "#dataframeClassSixNormalised = zeroOutDataframe(dataframeClassSixNormalised)\n",
    "#dataframeClassSixNormalised.loc[~(dataframeClassSixNormalised==0).all(axis=1)]\n",
    "#dataframeClassSixNormalised.insert(0,\"class\",6)\n",
    "\n",
    "dataframeClassSeven = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm\"),7))\n",
    "dataframeClassSeven = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-7/*.asm\",instructionList)\n",
    "dataframeClassSeven.to_csv(\"/home/eddy/machine-learning/data/datasetClassSeven.csv\")\n",
    "#dataframeClassSeven = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "dataframeClassSeven = zeroOutDataframe(dataframeClassSeven)\n",
    "dataframeClassSeven.loc[~(dataframeClassSeven==0).all(axis=1)]\n",
    "dataframeClassSeven.insert(0,\"class\",7)\n",
    "#dataframeClassSevenNormalised = dataframeClassSeven.div(dataframeClassSeven.sum(axis=1), axis=0)\n",
    "#dataframeClassSevenNormalised = zeroOutDataframe(dataframeClassSevenNormalised)\n",
    "#dataframeClassSevenNormalised.loc[~(dataframeClassSevenNormalised==0).all(axis=1)]\n",
    "#dataframeClassSevenNormalised.insert(0,\"class\",7)\n",
    "\n",
    "dataframeClassEight = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm\"),8))\n",
    "dataframeClassEight = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-8/*.asm\",instructionList)\n",
    "dataframeClassEight.to_csv(\"/home/eddy/machine-learning/data/datasetClassEight.csv\")\n",
    "#dataframeClassEight = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "dataframeClassEight = zeroOutDataframe(dataframeClassEight)\n",
    "dataframeClassEight.loc[~(dataframeClassEight==0).all(axis=1)]\n",
    "dataframeClassEight.insert(0,\"class\",8)\n",
    "#dataframeClassEightNormalised = dataframeClassEight.div(dataframeClassEight.sum(axis=1), axis=0)\n",
    "#dataframeClassEightNormalised = zeroOutDataframe(dataframeClassEightNormalised)\n",
    "#dataframeClassEightNormalised.loc[~(dataframeClassEightNormalised==0).all(axis=1)]\n",
    "#dataframeClassEightNormalised.insert(0,\"class\",8)\n",
    "\n",
    "dataframeClassNine = generateClassDataFrame(instructionList,cleanFileNameList(listFilesInDirectory(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm\"),9))\n",
    "dataframeClassNine = populateMalwareDataframe(\"/home/eddy/machine-learning/data/dataset-subset/class-9/*.asm\",instructionList)\n",
    "dataframeClassNine.to_csv(\"/home/eddy/machine-learning/data/datasetClassNine.csv\")\n",
    "#dataframeClassNine = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "dataframeClassNine = zeroOutDataframe(dataframeClassNine)\n",
    "dataframeClassNine.loc[~(dataframeClassNine==0).all(axis=1)]\n",
    "dataframeClassNine.insert(0,\"class\",9)\n",
    "#dataframeClassNineNormalised = dataframeClassNine.div(dataframeClassNine.sum(axis=1), axis=0)\n",
    "#dataframeClassNineNormalised = zeroOutDataframe(dataframeClassNineNormalised)\n",
    "#dataframeClassNineNormalised.loc[~(dataframeClassNineNormalised==0).all(axis=1)]\n",
    "#dataframeClassNineNormalised.insert(0,\"class\",9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd53ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframesNormalisedList = [dataframeClassOneNormalised,dataframeClassTwoNormalised,dataframeClassThreeNormalised,dataframeClassFourNormalised,dataframeClassFiveNormalised,dataframeClassSixNormalised,dataframeClassSevenNormalised,dataframeClassEightNormalised,dataframeClassNineNormalised]\n",
    "dataframesList = [dataframeClassOne,dataframeClassTwo,dataframeClassThree,dataframeClassFour,dataframeClassFive,dataframeClassSix,dataframeClassSeven,dataframeClassEight,dataframeClassNine]\n",
    "finalDF = pd.concat(dataframesList).drop_duplicates()\n",
    "finalDF = finalDF.drop([\"assume\",\"align\"],axis=1) # Error, seems like they're gone already\n",
    "finalDF = zeroOutDataframe(finalDF)\n",
    "finalDF.loc[~(finalDF==0).all(axis=1)]\n",
    "finalDF = finalDF.loc[:, (finalDF != 0).any(axis=0)] # Removes columns with no values\n",
    "finalDF = finalDF.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e5ba3",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing sklearn and getting basic info about my training set\n",
    "#Merge all data into one DF with labels intact\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "finalDF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09a03b",
   "metadata": {},
   "source": [
    "## Splitting the data into train+test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3795c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing up the dataset into train, validate and test sets\n",
    "trainDF, testAndValidDF = train_test_split(finalDF, test_size=0.4)\n",
    "testDF, validDF = train_test_split(testAndValidDF, test_size=0.5)\n",
    "\n",
    "print(f\"Training Dataset rows and columns: {trainDF.shape}\")\n",
    "print(f\"Test Dataset rows and columns: {testDF.shape}\")\n",
    "print(f\"Validation Dataset rows and columns: {validDF.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cda6a",
   "metadata": {},
   "source": [
    "## Training Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "#not doing sns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating training stats based on the trainDF dataset\n",
    "trainStats = trainDF.describe()\n",
    "trainStats.pop(\"class\")\n",
    "trainStats = trainStats.transpose()\n",
    "trainStats.to_csv(\"/home/eddy/traindata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbae27eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "trainLabels = trainDF.pop(\"class\")\n",
    "testLabels = testDF.pop(\"class\")\n",
    "validLabels = validDF.pop(\"class\")\n",
    "\n",
    "print(len(trainLabels))\n",
    "print(len(testLabels))\n",
    "print(len(validLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d56d5",
   "metadata": {},
   "source": [
    "## Data Normalisation/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(data):\n",
    "    #return (data -trainStats[\"mean\"]) / trainStats['std'] #Works fine, experimenting with the OTHER\n",
    "    return data\n",
    "    #return data.div(data.sum(axis=1), axis=0)\n",
    "\n",
    "normalisedTrainDF = normaliseData(trainDF)\n",
    "normalisedTestDF = normaliseData(testDF)\n",
    "normalisedValidDF = normaliseData(validDF)\n",
    "\n",
    "normalisedTrainDF = normalisedTrainDF.replace(np.nan,0)\n",
    "normalisedTestDF = normalisedTestDF.replace(np.nan,0)\n",
    "normalisedValidDF = normalisedValidDF.replace(np.nan,0)\n",
    "normalisedTrainDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f80820",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier\n",
    "model = svm.SVC(C = 1.5,\n",
    "                kernel='linear')\n",
    "modelPoly = svm.SVC(C = 1.5,\n",
    "                   kernel='poly')\n",
    "modelRBF = svm.SVC(C = 1.5,\n",
    "                   kernel='rbf')\n",
    "modelSig = svm.SVC(C = 1.5,\n",
    "                   kernel='sigmoid')\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(normalisedTrainDF, trainLabels)\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(normalisedTrainDF)\n",
    "\n",
    "modelPoly.fit(normalisedTrainDF, trainLabels)\n",
    "y_predPoly = modelPoly.predict(normalisedTrainDF)\n",
    "\n",
    "modelRBF.fit(normalisedTrainDF, trainLabels)\n",
    "y_predRBF = modelRBF.predict(normalisedTrainDF)\n",
    "\n",
    "modelSig.fit(normalisedTrainDF, trainLabels)\n",
    "y_predSig = modelSig.predict(normalisedTrainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleBatch = normalisedTestDF[:10]\n",
    "\n",
    "exampleResult = model.predict(exampleBatch)\n",
    "\n",
    "print(pd.Series(list(exampleBatch.index),index=exampleResult).to_string())\n",
    "print(f\"Predicted values: {exampleResult}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426cde3",
   "metadata": {},
   "source": [
    "## Checking how training went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#print(normalisedTrainDF.shape)\n",
    "normalisedTrainDF = normalisedTrainDF[np.isfinite(normalisedTrainDF).all(1)]\n",
    "#print(normalisedTrainDF.shape)\n",
    "\n",
    "#print(len(y_pred))\n",
    "#y_pred = model.predict(normalisedTrainDF)\n",
    "print(\"Linear Train Accuracy: \",metrics.accuracy_score(trainLabels,y_pred))\n",
    "print(\"Poly Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predPoly))\n",
    "print(\"RBF Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predRBF))\n",
    "print(\"Sigmoid Train Accuracy: \",metrics.accuracy_score(trainLabels,y_predSig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34661fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newNormalisedValidDF = zeroOutDataframe(normalisedValidDF)\n",
    "#newNormalisedValidDF = newNormalisedValidDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "#y_pred = model.predict(newNormalisedValidDF)\n",
    "y_pred = model.predict(newNormalisedValidDF)\n",
    "print(\"Linear Valid Accuracy: \",metrics.accuracy_score(validLabels,y_pred))\n",
    "print(\"Linear Valid Accuracy: \",metrics.accuracy_score(validLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newNormalisedTestDF = zeroOutDataframe(normalisedTestDF)\n",
    "#newNormalisedTestDF = newNormalisedTestDF.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "\n",
    "y_pred = model.predict(newNormalisedTestDF)\n",
    "print(\"Test Accuracy: \",metrics.accuracy_score(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "predictResults = model.predict(newNormalisedTestDF)\n",
    "cm = confusion_matrix(predictResults,predictResults)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix - Linear\")\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax=ax); #Semicolon removes the annoying text above the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testLabels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278ca04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435f01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
